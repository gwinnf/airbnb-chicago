{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ea7d6e-99e9-4931-a0db-5b62c080401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262914ef-7869-4fed-a686-8fe3e7a7b509",
   "metadata": {},
   "source": [
    "Possible business questions:\n",
    "\n",
    "- What factors contribute most heavily to the price? Make a model to predict the price - one that's interpretable and perhaps one (like a neural network) that's not interpretable but does a better job of price prediction. Which listings are underpriced - meaning that the host could make more money by increasing the price, or travelers can get a good deal by booking them?\n",
    "- What should those listings with poor overall review scores do in order to get better reviews in the future?\n",
    "- What can we discern about the character of each neighborhood using the descriptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78bf8b5d-1748-4048-b13a-1bdd0d20ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = pd.read_csv(\"listings.csv\")\n",
    "calendar = pd.read_csv(\"calendar.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4987c3-2fc6-4dad-8eea-5576531dd28c",
   "metadata": {},
   "source": [
    "Definitions for many (though not all) of the fields can be found [here](https://docs.google.com/spreadsheets/d/1iWCNJcSutYqpULSQHlNyGInUvHg2BoUGoNRIGa6Szc4/edit#gid=982310896)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8025aaaa-b151-4fca-98b7-332d406373c0",
   "metadata": {},
   "source": [
    "Drop columns that have all `NA` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358ae4a7-389c-4d41-9ad6-33f70f44c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [listings, calendar]:\n",
    "    df.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe63894-e9c5-49ea-8a3c-a07800214ca2",
   "metadata": {},
   "source": [
    "Drop rows in `listings` that have `NA` in the `price` field, and do the same for the `price` and `adjusted_price` fields in `calendar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ffeaf67-1012-461c-8b30-16f26027b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.dropna(subset=['price'], inplace=True)\n",
    "calendar.dropna(subset=['price', 'adjusted_price'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c335c87d-41ed-46b5-a22a-38f04705d102",
   "metadata": {},
   "source": [
    "Observe that a dollar sign preceeds the number in several columns; I will remove this so that the field is treated as numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3de6e499-bdaf-492e-8035-a35557e73e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['price'] = listings.apply((lambda x: x['price'].replace('$','').replace(',','')), axis=1)\n",
    "calendar['price'] = calendar.apply((lambda x: x['price'].replace('$','').replace(',','')), axis=1)\n",
    "calendar['adjusted_price'] = calendar.apply((lambda x: x['adjusted_price'].replace('$','').replace(',','')), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e41445b3-add9-4fe9-b68a-2ae7242771dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['price'] = listings['price'].astype(np.float64)\n",
    "calendar['price'] = calendar['price'].astype(np.float64)\n",
    "calendar['adjusted_price'] = calendar['adjusted_price'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54bfd3c-ed31-4a89-8085-f9a92cccafcd",
   "metadata": {},
   "source": [
    "Similarly, some of the fields are expressed as percentages; I will remove the percent signs and change the entries to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2b83a07-5d03-491e-b74a-a976bc3c23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings['host_response_rate'] = listings.apply(lambda x: float(x['host_response_rate'].replace('%','')) if pd.notnull(x['host_response_rate']) else x['host_response_rate'], axis=1)\n",
    "listings['host_acceptance_rate'] = listings.apply(lambda x: float(x['host_acceptance_rate'].replace('%','')) if pd.notnull(x['host_acceptance_rate']) else x['host_acceptance_rate'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762eaa6d-f6d4-40bf-8d20-73f98032cc5d",
   "metadata": {},
   "source": [
    "## 1. Price prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71bd5f-aa5f-4c23-a05f-b99e3b4aa96d",
   "metadata": {},
   "source": [
    "Split into `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef4ef4b-d851-4f12-8aea-241256a44cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = listings.drop('price', axis=1)\n",
    "y = listings['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd175db8-e611-496d-9a17-0f1483329d25",
   "metadata": {},
   "source": [
    "I also need to deal with dates appropriately. The relevant columns are `host_since`, `first_review`, and `last_review`. I could scrap these columns altogether, but it might be useful to know the length of time since the date for each row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89443ae0-4882-40db-a358-f1c5a34b70cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['host_since', 'first_review', 'last_review']:\n",
    "    X[col] = pd.to_datetime(X['last_scraped']) - pd.to_datetime(X[col])\n",
    "    X[col] = X.apply(lambda x: x[col].days, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa503c8-f71e-490f-b5dc-6d6b8e3bcb04",
   "metadata": {},
   "source": [
    "Certain columns in `X` are not useful for prediction (for example, URLs), and should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abd1ca9d-c86b-401f-bcec-07451c24b1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['id', 'listing_url', 'scrape_id', 'last_scraped', 'name']\n",
    "to_drop += ['description', 'neighborhood_overview', 'picture_url', 'host_id']\n",
    "to_drop += ['host_url', 'host_name', 'host_about', 'host_thumbnail_url']\n",
    "to_drop += ['host_picture_url', 'license', 'calendar_last_scraped']\n",
    "X.drop(labels=to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9d2727-84b3-4e33-85f0-e3e11210659c",
   "metadata": {},
   "source": [
    "Certain columns (`host_verifications` and `amenities`) are lists of options; I'd like to split these into different columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b3b9a0-3141-4910-8b72-02e4bc6290d2",
   "metadata": {},
   "source": [
    "The first step is to change these entries into actual Python lists instead of strings (annoyingly, the two relevant columns are formatted slightly differently, with the roles of single and double quotes being interchanged between them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cbc2268-3648-407e-9621-6627c55b79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['host_verifications'] = X.apply(lambda x: x['host_verifications'].replace('[','').replace(']','').replace('\\'','').split(', '), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2e6b600-ea6b-4d4a-8603-bf5bc1234809",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['amenities'] = X.apply(lambda x: x['amenities'].replace('\\\"','').replace('[','').replace(']','').split(', '), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2698ee50-43e7-41f8-99f3-ee4997ff33dc",
   "metadata": {},
   "source": [
    "What are the possible values in the `host_verifications` lists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaa0c652-b32e-4415-a36f-64faa1dbd4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_host_verifications = set()\n",
    "def find_distinct_hvs(x):\n",
    "    for hv in x['host_verifications']:\n",
    "        distinct_host_verifications.add(hv)\n",
    "X.apply(lambda x: find_distinct_hvs(x), axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e92d30df-fea2-4509-9e8d-15234493020e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distinct_host_verifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3a8bb54-90a9-469c-ba3d-a45a992a18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "031dfc2f-bfc9-4fda-bef9-0785073a13af",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MultiLabelBinarizer()\n",
    "hv_df = pd.DataFrame(m.fit_transform(X['host_verifications']), columns=m.classes_, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a336ddf-3712-4513-bbba-690f829a4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, hv_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3a9a3c3-9808-4ec2-80ab-e1c1ac172735",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.rename(columns={'None' : 'HV_None'}, inplace=True)\n",
    "# I don't want a column to be called just 'None', so I changed it a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06806fd4-6a80-42d8-8140-6baadd78cd41",
   "metadata": {},
   "source": [
    "Now I can drop the original `host_verifications` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "985685e2-1c99-4e74-887b-4f88c3fee6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('host_verifications', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40c2804-9179-4d19-ae71-d3ad79442f0e",
   "metadata": {},
   "source": [
    "Now I'd like to do the same for the `amenities` column. What are the possible values in those lists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d6ccb94-e610-4048-92c9-3158e4501f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_amenities = set()\n",
    "def find_distinct_amenities(x):\n",
    "    for a in x['amenities']:\n",
    "        distinct_amenities.add(a)\n",
    "X.apply(lambda x: find_distinct_amenities(x), axis=1)\n",
    "len(distinct_amenities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe76a8f-72c9-4a6f-b8f8-903527f634a9",
   "metadata": {},
   "source": [
    "Ok, that's a lot of amenities. I don't really want to vastly blow up the number of features like this, so I'll just take the 20 most popular amenities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0af64618-da78-4bd1-a9fe-efb55ac6b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "651e483a-62bd-4d0b-a686-ec5994a2a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "amenity_counts = defaultdict(int) # Initializes to zero for each value\n",
    "def update_counts(x):\n",
    "    for a in x['amenities']:\n",
    "        amenity_counts[a] += 1\n",
    "X.apply(lambda x: update_counts(x), axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6daa5a2-d820-4e4a-8d8a-0ef75ff9eddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20 = sorted(amenity_counts.items(), key=itemgetter(1), reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "362ec2af-4d26-4a02-9a11-04fb13484edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Smoke alarm', 6359),\n",
       " ('Essentials', 6185),\n",
       " ('Wifi', 6141),\n",
       " ('Kitchen', 5930),\n",
       " ('Carbon monoxide alarm', 5926)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "825e5a75-214c-4b69-8f64-1548e80240e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_amenities = dict(top_20).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097030e8-d085-40e1-9906-7ac2372b23d6",
   "metadata": {},
   "source": [
    "Now I want to get rid of the other amenities in each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0d24ed5-1792-451f-b023-74f75c5cf076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_amenities(x):\n",
    "    amenities = []\n",
    "    for a in top_20_amenities:\n",
    "        if a in x['amenities']:\n",
    "            amenities.append(a)\n",
    "    return amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ace5a3dc-9d0d-4a22-8fbf-25df50d81aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['amenities'] = X.apply(lambda x: find_amenities(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a323e83-1fed-49c0-b587-6736d9afe595",
   "metadata": {},
   "source": [
    "Now I can create the dummy variables and drop the original `amenities` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad38d0f0-6d9c-4b1d-aaad-cc7ed46a3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MultiLabelBinarizer()\n",
    "amenities_df = pd.DataFrame(m.fit_transform(X['amenities']), columns=m.classes_, index=X.index)\n",
    "X = pd.concat([X, amenities_df], axis=1)\n",
    "X.drop('amenities', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e20b28-94fb-4979-8e53-cd2fb76bb944",
   "metadata": {},
   "source": [
    "Next, I'll get dummies for the rest of the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f84187d-94a2-43a2-8212-e215ca63ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e291264c-58f0-46c6-b5c8-36a69f4577d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6528, 753)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece9c6f-0a41-4ee2-b38f-f163985ea5a3",
   "metadata": {},
   "source": [
    "Now I need to deal with `NA` values for the numeric columns. There's no totally ideal way to do this, but to move forward I'll impute using the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4622fcd9-1195-4c5c-837b-c00928d05715",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mean = lambda col: col.fillna(col.mean())\n",
    "X = X.apply(fill_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce67ff65-745c-4bd4-9af7-624d6c2911ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
